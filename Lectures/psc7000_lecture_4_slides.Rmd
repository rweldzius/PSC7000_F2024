---
title: "Uncertainty"
subtitle: "How confident are we?"
author: "Prof. Weldzius"
institute: "Villanova University"
date: "Slides Updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    # self_contained: true
    chakra: libs/remark-latest.min.js
    lib_dir: libs
    css:
      - default
      - css/lexis.css
      - css/lexis-fonts.css
    #seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
      ratio: "16:9"

---

```{css,echo = F}
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
```

```{r,include=F}
set.seed(123)
options(width=60)
knitr::opts_chunk$set(fig.align='center',fig.width=9,fig.height=5,message=F,warning=F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

# Agenda

1. Uncertainty

2. More NBA data

3. Bootstrap Sampling

---

# The Missing Ingredient

--

- Thus far we have:

--

  1. Tested whether **selective** schools have **higher SAT scores**: .blue[Yes]
  
  2. Tested Trump's theory that **polls were biased against him**: .blue[No]
  
  3. Tested whether RDD polls **contact more Trump supporters**: .blue[No]
  
  4. Tested whether state polls **accurately predicted the president**: .blue[No]
  
--

- We want to do more than say "Yes" or "No" when answering a .blue[Research Question] or making a .red[Prediction]

--

- We want to express our **confidence**

---

# What is "confidence"?

- In frequentist statistics:

--

  - How often your conclusion would be correct if you were able to run an "experiment" many times

--

  - How often your conclusion would be correct if you were able to observe the world many times
  
--

- .blue[Research Question]: Are NBA players in their rookie season more prone to turnovers?

--

  - .blue[Theory]: ??
  
  - .blue[Hypothesis]: ??
  
--

- .red[Analysis]: compare `tov` by `isRookie`
  
---

# NBA Example

```{r,message=F,warning=F}
require(tidyverse)
nba <- read_rds('https://github.com/rweldzius/psc7000_F2024/raw/main/Data/nba_players_2018.Rds')
glimpse(nba %>% select(tov,isRookie))
```

---

# Look

```{r}
summary(nba %>% select(tov,isRookie))
```

---

# Visualize: Univariate $Y$

```{r}
nba %>%
  ggplot(aes(x = tov)) + 
  geom_density()
```

---

# Visualize: Univariate $X$

```{r}
nba %>%
  count(isRookie) %>%
  ggplot(aes(x = n,y = isRookie)) + 
  geom_bar(stat = 'identity')
```

---

# Visualize: Multivariate

- Option #1: `summarise()` data prior to plotting

```{r,fig.height=4}
nba %>%
  group_by(isRookie) %>% 
  summarise(meanTOV = mean(tov,na.rm=T)) %>% #<<
  ggplot(aes(x = isRookie,y = meanTOV)) + 
  geom_bar(stat = 'identity')
```

---

# Visualize: Multivariate

- Option #2: plot raw data

```{r,fig.height=4}
nba %>%
  ggplot(aes(x = isRookie,y = tov)) + 
  geom_boxplot()
```
---

# Uncertainty

--

- Are rookies **better** than more senior players?

--

- Big philosophical step back

--

  - We live in a stochastic universe!
  
<center><img src="http://marcosagarcia.com/project/stochastic/featured.jpg" width=40%></center>

---

# Uncertainty

- Are rookies **better** than more senior players?

--

- Populations versus samples
  
--

  - Intro stats: uncertainty due to **sample**
  
---

# Uncertainty

- Big philosophical step back

  - We live in a stochastic universe!
  
- What does **better** mean?

--

  - .blue[Theory]: An innate quality in greater abundance
  
--

  - .blue[Prediction]: If we had to bet on who turns over the ball less, who do we choose?
  
--

- How **confident** would we be with this bet?

---

# Uncertainty

- If the universe is inherently stochastic, we are inherently uncertain

--

  - We THINK rookies are more careful passers, but not 100% certain
  
--

- How to measure this?

--

  - Run 100 experimental seasons
  
--

  - Record turnovers for rookies and non-rookies for each season
  
--

  - Calculate how many times rookies turned the ball over less than non-rookies
  
--

- 90 seasons out of 100 &rarr; 90% confident / certainty

--

- 100 seasons out of 100 &rarr; 100%?

--

- **FUNDAMENTAL STOCHASTIC NATURE OF REALITY (FSNoR)**

---

# Uncertainty

--

- Running 100 experimental seasons is impossible

--

  1. We are not Adam Silver
  2. Even if we were Adam Silver, 100 seasons = a century of basketball!
  
--

<center><img src="figs/obiwan.gif" width = 50%></center>


---

# Uncertainty

- Running 100 experimental seasons is impossible

  1. We are not Adam Silver
  2. Even if we were Adam Silver, 100 seasons = a century of basketball!
  3. If we were God? 100 seasons with the same players?
  
--

- *STILL wouldn't be 100% certain due to **FSNoR***

--

  - (**F**undamental **S**tochastic **N**ature **o**f **R**eality)

---

# Uncertainty

--

- But we are data scientists

--

- Take 1 season of basketball but sample it randomly

--

- **Bootstrap sampling**

--

- .blue[Theory]: By mimicking the sampling process, we can simulate a God experiment

--

  - (NB: this goes much deeper. Uncertainty from bootstrap combines FSNoR + sampling uncertainty.)
  
--

- .red[Practice]: `sample_n()` + `for()` loops

---

# Bootstrap Demo Step 1

- One randomly sampled player via `sample_n(size,replace)`

--

  - `size`: how many samples (from 1 to all observations)
  
  - `replace`: whether to put the sample back (`TRUE` or `FALSE`)

```{r}
set.seed(123) # Ensure we can reproduce results exactly

nba %>%
  sample_n(size = 1,replace = T) %>% 
  select(namePlayer,slugSeason,isRookie,tov)
```

---

# Bootstrap Demo Step 2

- Two randomly sampled players

```{r}
set.seed(123)
nba %>%
  sample_n(size = 1,replace = T) %>% select(namePlayer,slugSeason,isRookie,tov)

nba %>%
  sample_n(size = 1,replace = T) %>% select(namePlayer,slugSeason,isRookie,tov)
```

---

# Bootstrap Demo Step 2

- OR two randomly sampled players

```{r}
set.seed(123)

nba %>%
  sample_n(size = 2,replace = T) %>% select(namePlayer,slugSeason,isRookie,tov)
```


---

# Bootstrap Demo Step 3

- Randomly sample all players: `size = nrow(nba)` (or `nrow(.)`)


```{r}
set.seed(123)

nba %>%
  sample_n(size = nrow(nba),replace = T) %>% # Same as nrow(.)
  select(namePlayer,slugSeason,isRookie,tov)
```

---

# Bootstrap Demo Step 4

- Linking to **confidence**: Do we draw the same conclusion twice?

```{r}
set.seed(123)

# Bootstrapped Season #1
bsSeason1 <- nba %>%
  sample_n(size = nrow(.),replace = T) %>%
  select(isRookie,tov) %>%
  mutate(bsSeason = 1)

# Bootstrapped Season #2
bsSeason2 <- nba %>%
  sample_n(size = nrow(.),replace = T) %>%
  select(isRookie,tov) %>%
  mutate(bsSeason = 2)
```

---

# Bootstrap Demo Step 4

- Linking to **confidence**: Do we draw the same conclusion twice?

```{r}
bsSeason1 %>%
  group_by(isRookie) %>%
  summarise(mean_tov = mean(tov))

bsSeason2 %>%
  group_by(isRookie) %>%
  summarise(mean_tov = mean(tov))
```

---

# Bootstrap Demo Step 5

- Want to do this 100 times!

--

- Use a `for()` loop to make it cleaner

--

- A `for()` loop repeats the same code multiple times

--

  - Benefit: don't need to copy and paste a chunk of code 100 times
  
  - Just put a chunk of code in a loop that repeats 100 times!

```{r}
set.seed(123) # Ensure you'll get the same results each time
bsSeasons <- NULL # Instantiate empty object
for(bsSeason in 1:100) { # Repeat 100 times
  tmpSeason <- nba %>%
    sample_n(size = nrow(.),replace = T) %>% # Sample the data
    select(isRookie,tov) %>% # Select variables of interest
    mutate(bsSeasonNumber = bsSeason) # Save the simulation ID
  bsSeasons <- bind_rows(bsSeasons,tmpSeason) # Append to the empty object!
}
```


---

# Bootstrap to measure Confidence

--

- Compare rookie versus non-rookie turnovers each season

```{r}
bsSeasons %>%
  group_by(bsSeasonNumber,isRookie) %>%
  summarise(mean_tov = mean(tov),.groups = 'drop')
```

---

# Bootstrap to measure Confidence

- Compare rookie versus non-rookie turnovers each season

```{r,fig.width=9,fig.height=5}
bsSeasons %>%
  group_by(bsSeasonNumber,isRookie) %>%
  summarise(mean_tov = mean(tov),.groups = 'drop') %>%
  spread(isRookie,mean_tov) #<<
```


---

# Bootstrap to measure Confidence

- Compare rookie versus non-rookie turnovers each season

```{r,fig.width=9,fig.height=5}
bsSeasons %>%
  group_by(bsSeasonNumber,isRookie) %>%
  summarise(mean_tov = mean(tov),.groups = 'drop') %>%
  spread(isRookie,mean_tov) %>% #<<
  filter(complete.cases(.)) %>%
  mutate(rookieBetter = ifelse(`FALSE` > `TRUE`,1,0))
```

---

# Bootstrap to measure Confidence

- Compare rookie versus non-rookie turnovers each season

```{r,fig.width=9,fig.height=5}
(conf <- bsSeasons %>%
  group_by(bsSeasonNumber,isRookie) %>%
  summarise(mean_tov = mean(tov),.groups = 'drop') %>%
  spread(isRookie,mean_tov) %>% #<<
  filter(complete.cases(.)) %>%
  mutate(rookieBetter = ifelse(`FALSE` > `TRUE`,1,0)) %>%
  summarise(rookieBetter = mean(rookieBetter)))
```

--

- Rookies have fewer turnovers `r round(conf$rookieBetter*100,1)`% of the time! (How much do you bet on next season?)

---

# Other ways to use bootstraps

- Could plot the **distributions** for each group

```{r,warning=F,message=F,fig.height = 4, fig.width = 6}
 bsSeasons %>%
  group_by(bsSeasonNumber,isRookie) %>%
  summarise(mean_tov = mean(tov),.groups = 'drop') %>%
  ggplot(aes(x = mean_tov,fill = isRookie)) + 
  geom_density(alpha = .3)
```

---

# Other ways to use bootstraps

- Could plot the **distributions** of the "estimate"

```{r,warning=F,message=F}
p <- bsSeasons %>%
  group_by(bsSeasonNumber,isRookie) %>%
  summarise(mean_tov = mean(tov),.groups = 'drop') %>%
  spread(isRookie,mean_tov) %>% #<<
  mutate(estimate = `FALSE` - `TRUE`) %>%
  ggplot(aes(x = estimate)) + 
  geom_density(alpha = .3) + 
  geom_vline(xintercept = 0,linetype = 'dashed')
```

---

# Other ways to use bootstraps

- Could plot the **distributions** of the "estimate"

```{r,message = F,warning=F}
p
```

---

# Where to calculate the "estimate"

- **First** we created a new dataset of 100 simulated seasons

--

- **Then** we calculate average turnover % for rookies and veterans for each simulation

--

- **Finally** we calculate the difference between average turnover % of veterans and rookies for each simulation

--

- **BUT!** It is equally valid to calculate the "estimate" *within* the `for()` loop

```{r}
set.seed(123)
bsRes <- NULL
for(counter in 1:100) {
  tmpEst <- nba %>%
    sample_n(size = nrow(.),replace = T) %>%
    group_by(isRookie) %>%
    summarise(mean_tov = mean(tov,na.rm=T)) %>% #<<
    mutate(bsSeason = counter)
  
  bsRes <- bind_rows(bsRes,tmpEst)
}
```

---

# Where to calculate the "estimate"

```{r}
bsRes %>%
  ggplot(aes(x = mean_tov,fill = isRookie)) + 
  geom_density(alpha = .3)
```

---

# Where to calculate the "estimate"

```{r,warning=F,message=F,fig.height = 4, fig.width = 6}
bsRes %>%
  spread(isRookie,mean_tov) %>%
  mutate(rookieBetter = `FALSE` - `TRUE`) %>%
  ggplot(aes(x = rookieBetter)) + 
  geom_density(alpha = .3) + 
  geom_vline(xintercept = 0,linetype = 'dashed')
```

---

# Where to calculate the "estimate"

- Same confidence measure

```{r}
bsRes %>%
  spread(key = isRookie,value = mean_tov) %>%
  mutate(rookieBetter = ifelse(`FALSE` > `TRUE`,1,0)) %>%
  summarise(confidence = mean(rookieBetter,na.rm=T))
```

---

# Interpreting Confidence

- **Is this high?**

--

  - What value reflects the minimum confidence?
  
--

  - A coin flip &rarr; 50%
  
--

- What does a confidence level of 1 mean?

--

  - We are 100% confident?

---

# Do we believe this?

- Why might this conclusion be **spurious**?

--

- Rookies get less playing time

- Therefore fewer opportunities to turn the ball over

--

- Solution? Turnovers per minute (or hour)

---

# Re-evaluating

```{r}
nba <- nba %>%
  mutate(tov_hr = tov*60 / minutes) 

nba %>%
  group_by(isRookie) %>%
  summarise(tov_hr = mean(tov_hr))
```

---

# Re-evaluating

```{r}
set.seed(123)
bsRes <- NULL
for(counter in 1:100) {
  tmpEst <- nba %>%
    sample_n(size = nrow(.),replace = T) %>%
    group_by(isRookie) %>%
    summarise(mean_tov = mean(tov_hr,na.rm=T)) %>% #<<
    mutate(bsSeason = counter)
  
  bsRes <- bind_rows(bsRes,tmpEst)
}
```

---

# Re-evaluating

```{r}
bsRes %>%
  ggplot(aes(x = mean_tov,fill = isRookie)) + 
  geom_density(alpha = .3)
```

---

# Re-Evaluating

```{r}
bsRes %>%
  mutate(isRookie = ifelse(isRookie == TRUE,'Rookie','Not Rookie')) %>%
  spread(isRookie,mean_tov) %>%
  summarise(conf = mean(`Not Rookie` > Rookie))
```



---

# Other Applications

- Could do the same to express **confidence** in conclusions about:

--

  - The relationship between SAT scores and selective admissions
  
  - The relationship between MSM polls and anti-Trump bias
  
  - Whether state polls are good at predicting the 2020 president

---


# Let's take a break

<center><img src="figs/break1.jpeg" width = 40%></center>

---

# Second half of class

<center><img src="figs/letsgo.gif" width = 50%></center>

---

---

# Sports Analytics

- Previously, we looked at players

--

  - Specifically, `isRookie` and `tov`
  
  - But could try **many** other ideas
  
--

- Useful if we want a job scouting talent

- But what if we want to advise actual games?

--

  - **Game Data**!

---

# Other NBA Data

--

- Load the [`game_summary.Rds`](https://github.com/rweldzius/psc7000_F2024/raw/main/Data/game_summary.Rds) data

```{r,message=F,warning=F}
require(tidyverse)
gms <- read_rds('https://github.com/rweldzius/psc7000_F2024/raw/main/Data/game_summary.Rds')
gms
```

---

# Other NBA Data

- Contains data on every game played between 2016 and 2019

--

```{r,fig.width=9,fig.height=5}
gms %>%
  ggplot(aes(x = dateGame)) +
  geom_bar(stat = 'count')
```


---

# Other NBA Data

```{r}
glimpse(gms)
```

---

# Codebook

| Name         |                                          Description |
|--------------|-----------------------------------------------------:|
| idGame       |                                       Unique game id |
| yearSeason   | Which season? NBA uses ending year so 2016-17 = 2017 |
| dateGame     |                                     Date of the game |
| idTeam       |                                       Unique team id |
| nameTeam     |                                            Team Name |
| locationGame |                        Game location, H=Home, A=Away |
| tov          |                                      Total turnovers |
| pts          |                                         Total points |
| treb         |                                       Total rebounds |
| pctFG        |                                Field Goal Percentage |
| teamrest     |               How many days since last game for team |
| pctFT        |                                Free throw percentage |
| isWin        |                                   Won? TRUE or FALSE |
| ft_80        |      Team scored more than 80 percent of free throws |

---

# Codebook

--

- Which of these are categorical? Which are continuous?

--

  - Remember the **process**!
  
--

- `isWin` as an ordered binary

```{r}
gms %>%
  count(isWin)
```

---

# Codebook

- The same number for wins and losses?
  
```{r}
gms %>%
  select(idGame,nameTeam,dateGame,locationGame,isWin) %>% head()
```

--

- Each row is a **team-game** pair

--

  - I.e., the Cavs hosted the Knicks on October 25, 2016 and won!
  
---

# The Knicks

<center><img src="https://miro.medium.com/max/1215/1*SeZTaMMhZbrG6zV5wTzLqg.gif" width = 100%></center>

---

# .blue[Science]

--

- What predicts winning?

--

  - Points? (more is better)
  - Turnovers? (less is better)
  - Rebounds? (more is better)
  
--

- How confident are we?

```{r}
gms %>%
  group_by(isWin) %>%
  summarise(avgTO = mean(tov))
```

---

# Turnovers and Winning

--

- On average, winning teams have ~1 fewer turnover than losing teams

--

- FSNoR: is this *always* the case?

```{r}
gms %>%
  filter(yearSeason == 2017) %>%
  group_by(isWin) %>%
  summarise(avgTO = mean(tov))
```

---

# Turnovers and Winning

- On average, winning teams have ~1 fewer turnover than losing teams

- FSNoR: is this *always* the case?

```{r}
gms %>%
  filter(yearSeason == 2018) %>%
  group_by(isWin) %>%
  summarise(avgTO = mean(tov))
```

---

# Turnovers and Winning

- On average, winning teams have ~1 fewer turnover than losing teams

- FSNoR: is this *always* the case?

```{r}
gms %>%
  group_by(isWin,yearSeason) %>%
  summarise(avgTO = mean(tov)) %>%
  spread(isWin,avgTO,sep = '_')
```


---

# Turnovers and Winning

- On average, winning teams have ~1 fewer turnover than losing teams

- FSNoR: is this *always* the case?

--

  - Not literally (numbers change)

--

  - But practically?
  
- How **confident** are we in making this claim?

--

  - In each season, the average turnovers of winning teams are roughly 1 lower than the average turnovers of losing teams
  
--

  - Use **bootstrap sampling** to express this more concretely!
  

---

# Looping

```{r}
set.seed(123)
bs_tov <- NULL
for(i in 1:1000) {
  bs_tov <- gms %>%
    sample_n(size = 100,replace = T) %>%
    group_by(isWin) %>%
    summarise(avgTO = mean(tov)) %>%
    bind_rows(bs_tov)
}
bs_tov %>% head()
```

---

# Bootstrapped Estimates vs Data

```{r}
bs_tov %>%
  group_by(isWin) %>%
  summarise(bs_est = mean(avgTO))

gms %>%
  group_by(isWin) %>%
  summarise(data_est = mean(tov))
```

---

# Bootstrapped Estimates vs Data

--

- They're identical!

--

  - In .blue[theory], bootstrapped samples converge on true values
  
--

  - ...where "true" is the full data
  
--

- So then why bother with bootstrapping?

--

- **Uncertainty!**

---

# Plot Distributions of Bootstraps

```{r,fig.width=9,fig.height=5}
bs_tov %>%
  ggplot(aes(x = avgTO,fill = isWin)) + 
  geom_density(alpha = .3)
```

---

# Generalizability

--

- What if we only used one season?

--

  - Do we think our conclusions would "generalize" (i.e., apply to) other seasons?

--

  - For example, is the turnover-win relationship the same in the 2017 season as the 2018 season?
  
--

  - What about the 2019 season?
  
--

  - Why or why not?
  
--

- Demonstrate using the 2017 data

---

# Generalizability

- Bootstrap + `group_by`

```{r}
bsRes <- NULL

for(i in 1:500) {  # Only 500 simulations this time
  bsRes <- gms %>%
    group_by(yearSeason) %>% #<< Group by the season
    sample_n(size = 100,replace = T) %>% #<< Get 100 observations per season
    group_by(yearSeason,isWin) %>% #<< Then calculate mean tov by season AND win
    summarise(avgTO = mean(tov,na.rm=T),.groups = 'drop') %>%
    ungroup() %>%
    mutate(bsInd = i) %>%
    bind_rows(bsRes)
  
}

```

---

# Plotting the results

```{r}
bsRes %>%
  ggplot(aes(x = avgTO)) + 
  geom_density(alpha = .3)
```

--

- Is this answering our .blue[question]?

---

# Plotting the results

```{r}
bsRes %>%
  ggplot(aes(x = avgTO,fill = isWin)) + 
  geom_density(alpha = .3)
```

- Is this answering our .blue[question]?

---

# Plotting the results

```{r}
bsRes %>%
  ggplot(aes(x = avgTO,fill = isWin)) + 
  geom_density(alpha = .3) + 
  facet_grid(yearSeason~.)
```


---

# Plotting the results

```{r}
p  <- bsRes %>%
  ggplot(aes(x = avgTO,fill = isWin)) + 
  geom_density(alpha = .3) + 
  geom_vline(data = bsRes %>%  #<<
               group_by(yearSeason,isWin) %>%#<<
               summarise(avgTO = mean(avgTO,na.rm=T)),#<<
             aes(xintercept = avgTO,color = isWin),linetype = 'dashed') + #<<
  geom_text(data = bsRes %>%#<<
               group_by(yearSeason,isWin) %>%#<<
               summarise(avgTO = mean(avgTO,na.rm=T)),#<<
             aes(x = avgTO,y = Inf,label = round(avgTO,1)),hjust = 1.1,vjust = 1.1,size = 3,angle = 90) + #<<
  facet_grid(yearSeason~.)
```

---

# Plotting the results

```{r}
p
```

---

# Summarizing further

--

- We are *actually* interested in whether winning teams turnover the ball less

--

  - .blue[Science]: never forget your theory / hypothesis!
  
--

- So let's actually calculate this!

--

- The `spread` command to create two columns

```{r}
bsRes %>%
  spread(isWin,avgTO,sep = '_') %>%
  mutate(TO_diff = isWin_FALSE - isWin_TRUE)
```

---

# Generalizability

```{r}
bsRes %>%
  spread(isWin,avgTO,sep = '_') %>%
  mutate(TO_diff = isWin_FALSE - isWin_TRUE) %>%
  ggplot(aes(x = TO_diff,fill = factor(yearSeason))) + 
  geom_density(alpha = .3)
```

---

# Comparing across seasons

```{r}
p <- bsRes %>%
  spread(isWin,avgTO,sep = '_') %>%
  mutate(TO_diff = isWin_FALSE - isWin_TRUE) %>%
  ggplot(aes(x = TO_diff,group = yearSeason)) + 
  geom_density(alpha = .3) + 
  geom_vline(xintercept = 0) + 
  geom_text(data = bsRes %>%
             spread(isWin,avgTO,sep = '_') %>%
             mutate(TO_diff = isWin_FALSE - isWin_TRUE) %>%
             group_by(yearSeason) %>%
             summarise(conf = mean(TO_diff > 0),
                       TO_diff = mean(TO_diff),
                       y = .25),
            aes(x = TO_diff,y = y,label = paste0(round(conf*100,1),'%'))) + 
  facet_grid(yearSeason ~.)
```

---

# Comparing across seasons

```{r}
p
```


---

# Visualization is **DEEP**

```{r}
toplot <- bsRes %>%
  spread(isWin,avgTO,sep = '_') %>%
  mutate(TO_diff = isWin_FALSE - isWin_TRUE)

tmp <- density(toplot$TO_diff)
p <- data.frame(x = tmp$x,y = tmp$y, area = tmp$x >= 0) %>%
  ggplot(aes(x = x,ymin = 0,ymax = y,fill = area)) + 
  geom_ribbon(alpha = .6) + 
  geom_vline(xintercept = 0,linetype = 'dashed',size = 1.1) + 
  annotate(geom = 'text',x = mean(toplot$TO_diff),y = .25,
           label = paste0("Losing team had\nmore turnovers in\n",round(mean(toplot$TO_diff > 0),3)*100,"% of\nBootstraps"), #<<
           hjust = .5) + 
  labs(title = 'Difference in Turnovers by Game Outcome',
       subtitle = '1,000 Bootstrapped Estimates from 2016-2019 Seasons',
       x = 'Losing Team Turnovers minus Winning Team Turnovers',
       y = 'Density of Simulated Games') + 
  scale_fill_manual(name = 'Who Had More Turnovers',
                    values = c('grey60','slateblue'),labels = c('Winning Team','Losing Team')) + 
  theme(panel.background = element_blank(),
        legend.position = 'bottom')
```


---

# Visualization is **DEEP**

```{r,echo=F,fig.width=9,fig.height=6}
p
```


---

# Conclusion

--

- Anyone can spit stats

<center><img src="https://imgs.xkcd.com/comics/sports.png" width=25%></center>

--

- Data scientists are comfortable with **.blue[uncertainty]**


---

# Homework & Problem Set
  
  1. Work through psc7000_hw_4.Rmd 
  
  2. Problem Set 4 (due on Friday by 11:59pm; submit on Blackboard)
